# -*- coding: utf-8 -*-
"""Knowledge graph.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mSt5jkxOLk4tef8-FMWOgthpsQHnhEMk

Import Libraries
"""

import pandas as pd
import re
import bs4
import requests
import networkx as nx
import matplotlib.pyplot as plt
from tqdm import tqdm

import spacy
from spacy import displacy
from spacy.matcher import Matcher
from spacy.tokens import Span

nlp = spacy.load('en_core_web_sm')
pd.set_option('display.max_colwidth', 200)

sentences = pd.read_csv('data.csv')

"""Entity Extraction"""

def get_entities(sent):
    ## chunk 1
    ent1 = ""
    ent2 = ""
    prv_tok_dep = ""  
    prv_tok_text = ""  

    prefix = ""
    modifier = ""

    for tok in nlp(sent):

        ## chunk 2
        if tok.dep_ != "punct":
            if tok.dep_ == "compound":
                prefix = tok.text
                if prv_tok_dep == "compound":
                    prefix = prv_tok_text + " " + tok.text

            if tok.dep_.endswith("mod") == True:
                modifier = tok.text
                if prv_tok_dep == "compound":
                    modifier = prv_tok_text + " " + tok.text

            ## chunk 3
            if tok.dep_.find("subj") == True:
                ent1 = modifier + " " + prefix + " " + tok.text
                prefix = ""
                modifier = ""
                prv_tok_dep = ""
                prv_tok_text = ""

            ## chunk 4
            if tok.dep_.find("obj") == True:
                ent2 = modifier + " " + prefix + " " + tok.text

            ## chunk 5
            prv_tok_dep = tok.dep_
            prv_tok_text = tok.text

    return [ent1.strip(), ent2.strip()]

entity_pairs = []
for i in tqdm(sentences["sentence"]):
    entity_pairs.append(get_entities(i))

"""Relation Extraction"""

def get_relation(sent):
    doc = nlp(sent)
    matcher = Matcher(nlp.vocab)
    pattern = [{'DEP': 'ROOT'},
               {'DEP': 'prep', 'OP': "?"},
               {'DEP': 'agent', 'OP': "?"},
               {'POS': 'ADJ', 'OP': "?"}]
    matcher.add("matching_1", None, pattern)
    matches = matcher(doc)
    k = len(matches) - 1
    span = doc[matches[k][1]:matches[k][2]]
    return (span.text)
relations = [get_relation(i) for i in tqdm(sentences['sentence'])]
print(relations)

"""Extracting Nodes"""

source = [i[0] for i in entity_pairs]
target = [i[1] for i in entity_pairs]
kg_df = pd.DataFrame({'source':source, 'target':target, 'edge':relations})
print(kg_df)

"""Creating a directed-graph from a dataframe"""

G = nx.from_pandas_edgelist(kg_df, "source", "target", edge_attr=True, create_using=nx.MultiDiGraph())

plt.figure(figsize=(12, 12))
pos = nx.spring_layout(G)
nx.draw(G, with_labels=True, node_color='skyblue', edge_cmap=plt.cm.Blues, pos=pos)
plt.show()

G = nx.from_pandas_edgelist(kg_df[kg_df['edge'] == "composed by"], "source", "target", edge_attr=True, create_using=nx.MultiDiGraph())
plt.figure(figsize=(12, 12))
pos = nx.spring_layout(G, k=0.5)  
nx.draw(G, with_labels=True, node_color='skyblue', node_size=1500, edge_cmap=plt.cm.Blues, pos=pos)
plt.show()